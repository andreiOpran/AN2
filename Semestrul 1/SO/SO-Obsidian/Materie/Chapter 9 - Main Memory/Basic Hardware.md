
- Main memory and the registers built into each processing core are the only general-purpose storage that the CPU can access directly. There are machine instructions that take memory addresses as arguments, but none that take disk addresses. Therefore, any instructions in execution, and any data being used by the instructions, must be in one of these direct-access storage devices. If the data are not in memory, they must be moved there before the CPU can operate on them.
- Registers that are built into each CPU core are generally accessible within <span style="color:rgb(112, 48, 160)">one cycle</span> of the CPU clock. Some CPU cores can decode instructions and perform simple operations on register contents at the rate of one or more operations per clock tick.
- The same cannot be said of main memory, which is accessed via a transaction on the memory bus. Completing a memory access may take many cycles of the CPU clock. In such cases, the processor normally needs to <span style="color:rgb(112, 48, 160)">stall</span>, since it does not have the data required to complete the instruction that it is executing. This situation is <span style="color:rgb(112, 48, 160)">intolerable</span> because of the frequency of memory accesses. The remedy is to add fast memory between the CPU and main memory, typically on the CPU chip for fast access. Such a <span style="color:rgb(112, 48, 160)">cache</span> was described in Section 1.5.5. To manage a <span style="color:rgb(112, 48, 160)">cache</span> built into the CPU, the hardware automatically speeds up memory access without any operating-system control. (Recall from Section 5.5.2 that during a memory stall, a multithreaded core can switch from the stalled hardware thread to another hardware thread.)

- Not only are we concerned with the relative speed of accessing physical memory, but we also must ensure <span style="color:rgb(112, 48, 160)">correct operation</span>. For proper system operation, we must <span style="color:rgb(112, 48, 160)">protect the operating system from access by user processes</span>,<span style="color:rgb(112, 48, 160)"></span> as well as <span style="color:rgb(112, 48, 160)">protect user processes from one another</span>. This protection must be <span style="color:rgb(112, 48, 160)">provided by the hardware</span>, because the operating system doesnâ€™t usually intervene between the CPU and its memory accesses (because of the resulting <span style="color:rgb(112, 48, 160)">performance penalty</span>). Hardware implements this production in several different ways, as we show throughout the chapter. Here, we outline one possible implementation.
	- We first need to make sure that each process has a <span style="color:rgb(112, 48, 160)">separate memory space</span>. Separate per-process memory space protects the processes from each other and is fundamental to having multiple processes loaded in memory for concurrent execution. 
	- <span style="color:rgb(112, 48, 160)">To separate memory spaces</span>, we need the ability to determine the range of legal addresses that the process may access and to ensure that the process can access only these legal addresses. We can provide protection by using <span style="color:rgb(112, 48, 160)">two registers</span>, usually a <span style="color:rgb(112, 48, 160)">base</span> and a <span style="color:rgb(112, 48, 160)">limit</span>, as illustrated in Figure 9.1. 
	- ![[Pasted image 20250212193716.png]]
	- The <span style="color:rgb(112, 48, 160)">base</span> register holds the smallest legal physical memory address; the <span style="color:rgb(112, 48, 160)">limit</span> register specifies the size of the range. For example, if the base register holds 300040 and the limit register is 120900, then the program can legally access all addresses from 300040 through <span style="color:rgb(112, 48, 160)">420939</span> (inclusive).
