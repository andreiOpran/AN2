
- By far the <span style="color:rgb(112, 48, 160)">simplest</span> CPU-scheduling algorithm is the <span style="color:rgb(112, 48, 160)">first-come first-serve (FCFS)</span> scheduling algorithm. With this scheme, the process that requests the CPU first is allocated the CPU first. 
- The implementation of the <span style="color:rgb(112, 48, 160)">FCFS</span> policy is easily managed with a <span style="color:rgb(112, 48, 160)">FIFO</span> queue. 
	- When a process enters the ready queue, its PCB is linked onto the tail of the queue. 
	- When the CPU is free, it is allocated to the process at the head of the queue. 
	- The running process is then removed from the queue.
- On the <span style="color:rgb(112, 48, 160)">negative</span> side, the average <span style="color:rgb(112, 48, 160)">waiting time</span> under the FCFS policy is often <span style="color:rgb(112, 48, 160)">quite long</span>. Consider the following set of processes that arrive at time 0, with the length of the CPU burst given in milliseconds:
- ![[Pasted image 20250212003423.png]]
- If the processes arrive in the <span style="color:rgb(112, 48, 160)">order P1, P2, P3</span>, and are served in <span style="color:rgb(112, 48, 160)">FCFS</span> order, we get the result shown in the following <span style="color:rgb(112, 48, 160)">Gantt chart</span>:
- ![[Pasted image 20250212003516.png]]
- The waiting time is 0 milliseconds for process P1, 24 milliseconds for process P2, and 27 milliseconds for process P3. Thus, the average waiting time is (0 + 24 + 27)/3 = <span style="color:rgb(112, 48, 160)">17 milliseconds</span>. 
	- If the processes arrive in the <span style="color:rgb(112, 48, 160)">order P2, P3, P1</span>, however, the results will be as shown in the following<span style="color:rgb(112, 48, 160)"> Gantt chart</span>:
	- ![[Pasted image 20250212003601.png]]
	- The average waiting time is now (6 + 0 + 3)/3 = <span style="color:rgb(112, 48, 160)">3 milliseconds</span>. This reduction is <span style="color:rgb(112, 48, 160)">substantial</span>. Thus, the average waiting time under an <span style="color:rgb(112, 48, 160)">FCFS</span> policy is generally <span style="color:rgb(112, 48, 160)">not minimal </span>and may vary substantially if the processesâ€™ CPU<span style="color:rgb(112, 48, 160)"> burst times</span> vary greatly.

- <span style="color:rgb(112, 48, 160)">Note</span> also that the FCFS scheduling algorithm is <span style="color:rgb(112, 48, 160)">nonpreemptive</span>. Once the CPU has been allocated to a process, that process keeps the CPU until it releases the CPU, either by terminating or by requesting I/O.

- In addition, consider the performance of FCFS scheduling in a dynamic situation. Assume we have one CPU-bound process and many I/O-bound processes. As the processes flow around the system, the following scenario may result. The CPU-bound process will get and hold the CPU. During this time, all the other processes will finish their I/O and will move into the ready queue, waiting for the CPU. While the processes wait in the ready queue, the I/O devices are idle. Eventually, the CPU-bound process finishes its CPU burst and moves to an I/O device. All the I/O-bound processes, which have short CPU bursts, execute quickly and move back to the I/O queues. At this point, the CPU sits idle. The CPU-bound process will then move back to the ready queue and be allocated the CPU. Again, all the I/O processes end up waiting in the ready queue until the CPU-bound process is done. There is a convoy effect as all the other processes wait for the one big process to get off the CPU. This effect results in lower CPU and device utilization than might be possible if the shorter processes were allowed to go first.